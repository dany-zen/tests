{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga la base de datos\n",
    "\n",
    "Se trabaja con el módulo auxiliar process_data, el cual define una carga personalizada para estos ejemplos de ataques a modelos fedrados. Para más detalles sobre como efectuar la carga de datos con Flex ir a la documentación correspondiente.\n",
    "\n",
    "Este módulo permite la carga de dataset de procesamiento de imágenes como: Mnist, Fmnist, Cifar10 y Cifar100. Además del dataset tabular nursery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_data import *\n",
    "from copy import deepcopy\n",
    "\n",
    "flex_data, server_id = load_and_preprocess_horizontal(dataname=\"mnist\", trasnform=False, nodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se define la arquitectura de los modelos locales de los clientes. Para el presente ejemplo se trabaja con modelos neuronales de pytorch.\n",
    "\n",
    "Se utiliza el módulo networks_models, quien contiene una serie de modelos neuronales auxiliares de pytorch, para el trabajo con las bases de datos anteriormente mencionadas. Además se utiliza el módulo auxiliar networks_execution, que define la ejecución del entrenamiento y otros detalles de estos modelos.\n",
    "\n",
    "Para establecer un modelo personalizado, ir a la documentación de Flex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks_models import *\n",
    "from networks_execution import *\n",
    "from flex.pool import init_server_model\n",
    "from flex.model import FlexModel\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "net_config = ExecutionNetwork()\n",
    "\n",
    "@init_server_model\n",
    "def build_server_model():\n",
    "    server_flex_model = FlexModel()\n",
    "\n",
    "    criterion, model, optimizer = net_config.for_fd_server_model_config()\n",
    "\n",
    "    server_flex_model[\"model\"] = model.to(device)\n",
    "    # Required to store this for later stages of the FL training process\n",
    "    server_flex_model[\"criterion\"] = criterion\n",
    "    server_flex_model[\"optimizer_func\"] = optimizer\n",
    "    server_flex_model[\"optimizer_kwargs\"] = {}\n",
    "\n",
    "    return server_flex_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la arquitectura del modelo federado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import FlexPool\n",
    "clients = 2\n",
    "\n",
    "pool = FlexPool.client_server_pool(\n",
    "        fed_dataset= flex_data, server_id=server_id, init_func = build_server_model\n",
    "    )\n",
    "\n",
    "selected_test_clients_pool = pool.clients.select(clients)\n",
    "selected_test_clients = selected_test_clients_pool.clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la función para desplegar el modelo global en cada cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool.decorators import (  # noqa: E402\n",
    "    deploy_server_model,\n",
    ")\n",
    "from my_models_attacks.free_riding import free_riding_atck as fr\n",
    "\n",
    "rounds = 0\n",
    "round_global_model = None\n",
    "\n",
    "attack = fr(std_0 = 0, power = 1, decay = 1, multiplicator = 1)\n",
    "\n",
    "@deploy_server_model\n",
    "def deploy_serv(server_flex_model: FlexModel): \n",
    "\n",
    "    new_model = deepcopy(server_flex_model)\n",
    "    global round_global_model\n",
    "    if rounds == 0:\n",
    "        attack.set_model(deepcopy(server_flex_model[\"model\"]))\n",
    "\n",
    "    return new_model\n",
    "\n",
    "pool.servers.map(deploy_serv, selected_test_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se seleccionan los clientes free riding y los clientes normales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test import util_for_fr, util_for_fr_join_all\n",
    "\n",
    "list_of_fr = [0]\n",
    "\n",
    "free_riding_clients = pool.clients.select(lambda actor_id, set_of_roles: actor_id in list_of_fr)\n",
    "free_riding_clients = free_riding_clients.clients\n",
    "normal_clients = pool.clients.select(lambda actor_id, set_of_roles: actor_id not in list_of_fr)\n",
    "normal_clients = normal_clients.clients\n",
    "\n",
    "for i in free_riding_clients.actor_ids:\n",
    "    print(\"fr\",i)\n",
    "\n",
    "for i in normal_clients.actor_ids:\n",
    "    print(\"Normal\",i)\n",
    "#normal_clients, free_riding_clients = util_for_fr(list_of_fr, selected_test_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define el entrenamiento de un cliente free rider, como método de ataque. Para ello se utiliza el decorador model_poisoner, que define una directriz para los ataques de envenenamiento de modelos. Además se contabiliza las rondas de entrenamiento como parte del ataque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexclash.model import model_poisoner\n",
    "\n",
    "@model_poisoner\n",
    "def fr_attack(client_model: FlexModel):\n",
    "    print(\"Execute_fr_attack\")\n",
    "    prev = deepcopy(client_model[\"model\"])\n",
    "\n",
    "    previous_model_act = round_global_model\n",
    "\n",
    "    fr_model_client = attack.execute_attack(type_noise = \"disguised\", model = client_model[\"model\"], f_round= rounds)\n",
    "    \n",
    "    print(\"Suma de los paramtros de modelo fr por state dict:\", sum(param.sum() for param in fr_model_client.state_dict().values()))\n",
    "    print(\"Suma de los paramtros de modelo fr:\", sum(p.sum() for p in fr_model_client.parameters()))\n",
    "\n",
    "    print(\"Suma de los paramtros de modelo global fr por state dict:\", sum(param.sum() for param in prev.state_dict().values()))\n",
    "    print(\"Suma de los paramtros de modelo global fr:\", sum(p.sum() for p in prev.parameters()))\n",
    "\n",
    "    client_model[\"model\"] = fr_model_client\n",
    "    client_model[\"previous_model\"] = prev\n",
    "    try:\n",
    "        print(\"Suma de los paramtros de modelo global previo fr por state dict:\", sum(param.sum() for param in attack.first_server_model.state_dict().values()))\n",
    "        print(\"Suma de los paramtros de modelo global previo fr:\", sum(p.sum() for p in attack.first_server_model.parameters()))\n",
    "    except:\n",
    "        print(\"nulo\")\n",
    "\n",
    "    return client_model\n",
    "\n",
    "#free_riding_clients.map(fr_attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la ronda de entrenamiento local de un cliente, empleando el módulo networks_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
    "\n",
    "\n",
    "    train_dataset = client_data.to_torchvision_dataset(transform = mnist_transform())\n",
    "    client_dataloader = DataLoader(train_dataset, batch_size = 256)\n",
    "\n",
    "    model = client_flex_model[\"model\"]\n",
    "    model = model.to(device)\n",
    "\n",
    "    client_flex_model[\"previous_model\"] = deepcopy(model)\n",
    "    optimizer = client_flex_model[\"optimizer_func\"]\n",
    "    criterion = client_flex_model[\"criterion\"]\n",
    "\n",
    "    net_config.trainNetwork(local_epochs = 1, criterion = criterion, optimizer = optimizer,\n",
    "                            momentum = 0.9, lr = 0.005, trainloader = client_dataloader, testloader= None, \n",
    "                            model=model)\n",
    "    \n",
    "    return client_flex_model\n",
    "\n",
    "for i in normal_clients.actor_ids:\n",
    "    print(i)\n",
    "\n",
    "#normal_clients.map(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se efectúa la agregación del modelo federado. En este caso debe considerarse el resultado del entrenamiento tanto de los clientes free riding como los normales, para ello se empleará un método que unifique ambos clientes en un solo objeto flexPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool import collect_client_diff_weights_pt\n",
    "from flex.pool import fed_avg\n",
    "from flex.pool import set_aggregated_diff_weights_pt\n",
    "\n",
    "#pool.aggregators.map(collect_client_diff_weights_pt, selected_test_clients)\n",
    "#pool.aggregators.map(fed_avg)\n",
    "#pool.aggregators.map(set_aggregated_diff_weights_pt, pool.servers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalúa el modelo federado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_global_model(server_flex_model: FlexModel, test_data: Dataset):#falta poner esto\n",
    "    model = server_flex_model[\"model\"]\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    total_count = 0\n",
    "    model = model.to(device)\n",
    "    criterion = server_flex_model[\"criterion\"]\n",
    "    # get test data as a torchvision object\n",
    "    test_dataset = test_data.to_torchvision_dataset(transform = mnist_transform())\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset, batch_size=256, shuffle=True, pin_memory=False\n",
    "    )\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_dataloader):\n",
    "            total_count += target.size(0)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            losses.append(criterion(output, target).item())\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            test_acc += pred.eq(target.data.view_as(pred)).long().cpu().sum().item()\n",
    "\n",
    "    test_loss = sum(losses) / len(losses)\n",
    "    test_acc /= total_count\n",
    "    return test_loss, test_acc\n",
    "\n",
    "#metrics = pool.servers.map(evaluate_global_model)\n",
    "\n",
    "#loss, acc = metrics[0]\n",
    "#print(f\"Server: Test acc: {acc:.4f}, test loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para limpiar los modelos en memoria. Opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_models(client_model: FlexModel, _):\n",
    "    import gc\n",
    "\n",
    "    client_model.clear()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen las rondas de entrenamiento del modelo federado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_rounds(n_rounds, clients_per_round=20):\n",
    "    pool = FlexPool.client_server_pool(\n",
    "        fed_dataset= flex_data, server_id=server_id, init_func=build_server_model\n",
    "    )\n",
    "    global rounds\n",
    "    global round_global_model\n",
    "    print(rounds)\n",
    "    print(type(round_global_model))\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i+1} of {n_rounds}\")\n",
    "        selected_clients_pool = pool.clients.select(clients_per_round)\n",
    "        selected_clients = selected_clients_pool.clients\n",
    "        pool.servers.map(deploy_serv, selected_clients)\n",
    "\n",
    "        free_riding_clientss = selected_clients_pool.select(lambda actor_id, set_of_roles: actor_id in list_of_fr)\n",
    "        free_riding_clientss = free_riding_clientss.clients\n",
    "        normal_clientss = selected_clients_pool.select(lambda actor_id, set_of_roles: actor_id not in list_of_fr)\n",
    "        normal_clientss = normal_clientss.clients\n",
    "\n",
    "        free_riding_clientss.map(fr_attack)\n",
    "        normal_clientss.map(train)\n",
    "        \n",
    "        pool.aggregators.map(collect_client_diff_weights_pt, selected_clients)\n",
    "        pool.aggregators.map(fed_avg)\n",
    "        pool.aggregators.map(set_aggregated_diff_weights_pt, pool.servers)\n",
    "        metrics = pool.servers.map(evaluate_global_model)\n",
    "        selected_clients.map(clean_up_models)\n",
    "        loss, acc = metrics[0]\n",
    "        rounds+=1\n",
    "        print(f\"Server: Test acc: {acc:.4f}, test loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(5, clients_per_round=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
