{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga la base de datos\n",
    "\n",
    "Se trabaja con el módulo auxiliar process_data, el cual define una carga personalizada para estos ejemplos de ataques a modelos fedrados. Para más detalles sobre como efectuar la carga de datos con Flex ir a la documentación correspondiente.\n",
    "\n",
    "Este módulo permite la carga de dataset de procesamiento de imágenes como: Mnist, Fmnist, Cifar10 y Cifar100. Además del dataset tabular nursery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from process_data import *\n",
    "from copy import deepcopy\n",
    "\n",
    "flex_data, server_id = load_and_preprocess_horizontal(dataname=\"mnist\", trasnform=False, nodes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se define la arquitectura de los modelos locales de los clientes. Para el presente ejemplo se trabaja con modelos neuronales de pytorch.\n",
    "\n",
    "Se utiliza el módulo networks_models, quien contiene una serie de modelos neuronales auxiliares de pytorch, para el trabajo con las bases de datos anteriormente mencionadas. Además se utiliza el módulo auxiliar networks_execution, que define la ejecución del entrenamiento y otros detalles de estos modelos.\n",
    "\n",
    "Para establecer un modelo personalizado, ir a la documentación de Flex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks_models import *\n",
    "from networks_execution import *\n",
    "from flex.pool import init_server_model\n",
    "from flex.model import FlexModel\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "net_config = ExecutionNetwork()\n",
    "\n",
    "@init_server_model\n",
    "def build_server_model():\n",
    "    server_flex_model = FlexModel()\n",
    "\n",
    "    criterion, model, optimizer = net_config.for_fd_server_model_config()\n",
    "\n",
    "    server_flex_model[\"model\"] = model.to(device)\n",
    "    # Required to store this for later stages of the FL training process\n",
    "    server_flex_model[\"criterion\"] = criterion\n",
    "    server_flex_model[\"optimizer_func\"] = optimizer\n",
    "    server_flex_model[\"optimizer_kwargs\"] = {}\n",
    "\n",
    "    return server_flex_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define el ataque de envenamiento de datos por puerta trasera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes que modifica [0, 1]\n",
      "30000\n",
      "30000\n",
      "30000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "from flexclash.data import data_poisoner_all\n",
    "from my_poison_attacks.dirty_label import label_flipping_attack\n",
    "from PIL import Image\n",
    "\n",
    "client_ids = list(flex_data.keys())\n",
    "clients_to_backdoor = client_ids[:2]\n",
    "print(\"Clientes que modifica\", clients_to_backdoor)\n",
    "\n",
    "label_one = 1\n",
    "label_two = 2\n",
    "porcent_to_change = 0.2\n",
    "\n",
    "clients_to_change = clients_to_backdoor #Esto ver si funciona\n",
    "\n",
    "@data_poisoner_all\n",
    "def dirty_label_poison(dataset_client: Dataset):\n",
    "    x, y = dataset_client.to_numpy()#Ver como solo tomar las y\n",
    "    x = np.expand_dims(x, axis = 1)\n",
    "    \n",
    "    new_ylabels = label_flipping_attack(client_labels = y, num_labels = 10)\n",
    "\n",
    "    new_img_final = [Image.fromarray(x[arr][0]) for arr in range(len(x))]\n",
    "    print(len(new_img_final))\n",
    "    print(len(new_ylabels))\n",
    "\n",
    "    return new_img_final, new_ylabels\n",
    "\n",
    "flex_data_modif = flex_data.apply(dirty_label_poison, node_ids = clients_to_backdoor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la arquitectura del modelo federado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "(30000, 28, 28)\n",
      "[0, 1, 'server']\n"
     ]
    }
   ],
   "source": [
    "from flex.pool import FlexPool\n",
    "clients = 1\n",
    "\n",
    "pool = FlexPool.client_server_pool(\n",
    "        fed_dataset = flex_data_modif, server_id=server_id, init_func = build_server_model\n",
    "    )\n",
    "\n",
    "selected_test_clients_pool = pool.clients.select(clients)\n",
    "selected_test_clients = selected_test_clients_pool.clients\n",
    "\n",
    "print(selected_test_clients.actor_ids)\n",
    "print(np.array(flex_data_modif[selected_test_clients.actor_ids[0]].X_data).shape)\n",
    "#print(np.array(flex_data_modif[selected_test_clients.actor_ids[1]].X_data).shape)\n",
    "print(list(flex_data_modif.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la función para desplegar el modelo global en cada cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool.decorators import (  # noqa: E402\n",
    "    deploy_server_model,\n",
    ")\n",
    "\n",
    "@deploy_server_model\n",
    "def deploy_serv(server_flex_model: FlexModel): \n",
    "\n",
    "    new_model = deepcopy(server_flex_model)\n",
    "\n",
    "    return new_model\n",
    "\n",
    "pool.servers.map(deploy_serv, selected_test_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la ronda de entrenamiento local de un cliente, empleando el módulo networks_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:21<00:00,  5.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': CNN(\n",
       "   (conv1): Sequential(\n",
       "     (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     (1): LeakyReLU(negative_slope=0.2)\n",
       "   )\n",
       "   (conv2): Sequential(\n",
       "     (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "     (2): LeakyReLU(negative_slope=0.2)\n",
       "   )\n",
       "   (conv3): Sequential(\n",
       "     (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "     (2): LeakyReLU(negative_slope=0.2)\n",
       "   )\n",
       "   (out): Linear(in_features=2304, out_features=10, bias=True)\n",
       " ), 'criterion': CrossEntropyLoss(), 'optimizer_func': SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.05\n",
       "     maximize: False\n",
       "     momentum: 0.9\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ), 'optimizer_kwargs': {}, 'previous_model': CNN(\n",
       "   (conv1): Sequential(\n",
       "     (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     (1): LeakyReLU(negative_slope=0.2)\n",
       "   )\n",
       "   (conv2): Sequential(\n",
       "     (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "     (2): LeakyReLU(negative_slope=0.2)\n",
       "   )\n",
       "   (conv3): Sequential(\n",
       "     (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "     (2): LeakyReLU(negative_slope=0.2)\n",
       "   )\n",
       "   (out): Linear(in_features=2304, out_features=10, bias=True)\n",
       " )}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(client_flex_model: FlexModel, client_data: Dataset):\n",
    "\n",
    "    print(np.array(client_data.X_data).shape)\n",
    "    train_dataset = client_data.to_torchvision_dataset(transform = mnist_transform())\n",
    "    client_dataloader = DataLoader(train_dataset, batch_size = 256)\n",
    "\n",
    "    model = client_flex_model[\"model\"]\n",
    "    model = model.to(device)\n",
    "\n",
    "    client_flex_model[\"previous_model\"] = deepcopy(model)\n",
    "    optimizer = client_flex_model[\"optimizer_func\"]\n",
    "    criterion = client_flex_model[\"criterion\"]\n",
    "\n",
    "    net_config.trainNetwork(local_epochs = 1, criterion = criterion, optimizer = optimizer,\n",
    "                            momentum = 0.9, lr = 0.005, trainloader = client_dataloader, testloader= None, \n",
    "                            model=model)\n",
    "    \n",
    "    return client_flex_model\n",
    "\n",
    "selected_test_clients.map(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se efectúa la agregación del modelo federado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de la modif antes de fedavg tensor(2.2508)\n"
     ]
    }
   ],
   "source": [
    "from flex.pool import collect_client_diff_weights_pt\n",
    "from flex.pool import fed_avg\n",
    "from flex.pool import set_aggregated_diff_weights_pt\n",
    "\n",
    "\n",
    "pool.aggregators.map(collect_client_diff_weights_pt, selected_test_clients)\n",
    "pool.aggregators.map(fed_avg)\n",
    "pool.aggregators.map(set_aggregated_diff_weights_pt, pool.servers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evalúa el modelo federado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:04<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server: Test acc: 0.0045, test loss: 17.6161\n"
     ]
    }
   ],
   "source": [
    "def evaluate_global_model(server_flex_model: FlexModel, test_data: Dataset):#falta poner esto\n",
    "    model = server_flex_model[\"model\"]\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    total_count = 0\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "    criterion = server_flex_model[\"criterion\"]\n",
    "    # get test data as a torchvision object\n",
    "    dataset = test_data.to_torchvision_dataset(transform = mnist_transform())\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset, batch_size=256, shuffle=True, pin_memory=False\n",
    "    )\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_dataloader):\n",
    "            total_count += target.size(0)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            losses.append(criterion(output, target).item())\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            test_acc += pred.eq(target.data.view_as(pred)).long().cpu().sum().item()\n",
    "\n",
    "    test_loss = sum(losses) / len(losses)\n",
    "    test_acc /= total_count\n",
    "\n",
    "    \n",
    "    return test_loss, test_acc\n",
    "\n",
    "metrics = pool.servers.map(evaluate_global_model)\n",
    "\n",
    "loss, acc = metrics[0]\n",
    "print(f\"Server: Test acc: {acc:.4f}, test loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define el evaluador para el ataque\n",
    "\n",
    "Se selecciona como datos envenenados, aquellas imágenes generadas por el ataque. Verificando como se comporta el modelo si solo analiza aquellas imágenes modificadas. Al igual que en el notebook de ataques backdoors, puede insertar una función trigger para que genere nuevos datos a partir de imágenes, utilizando para ello el decorador generate_bad_data_for_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:03<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server: Test acc: 0.9676, test loss: 0.1091\n"
     ]
    }
   ],
   "source": [
    "from poison_attack_evaluator import generate_bad_data_for_test, evaluate_model_with_poison_data, data_poison_evaluator_pt\n",
    "from PIL import Image\n",
    "\n",
    "@generate_bad_data_for_test\n",
    "def poison_test_set(test_set: Dataset):\n",
    "    \n",
    "    x, y = test_set.to_numpy()#Ver como solo tomar las y\n",
    "    x = np.expand_dims(x, axis = 1)\n",
    "    \n",
    "    new_ylabels = label_flipping_attack(client_labels = y, num_labels = 10)\n",
    "\n",
    "    new_img_final = [Image.fromarray(x[arr][0]) for arr in range(len(x))]\n",
    "    print(len(new_img_final))\n",
    "    print(len(new_ylabels))\n",
    "\n",
    "\n",
    "    return new_img_final, new_ylabels\n",
    "\n",
    "@evaluate_model_with_poison_data\n",
    "def evaluator_pt(server_model: FlexModel, test_data: Dataset):\n",
    "    poison_dataset = poison_test_set(test_data)\n",
    "    poison_dataset = poison_dataset.to_torchvision_dataset(transform = mnist_transform())\n",
    "    test_loss, test_acc = data_poison_evaluator_pt(server_model, poison_dataset)\n",
    "    \n",
    "    return test_loss, test_acc\n",
    "\n",
    "metrics_for_bad_data = pool.servers.map(evaluator_pt)\n",
    "\n",
    "loss_b, acc_b = metrics_for_bad_data[0]\n",
    "print(f\"Server: Test acc: {acc_b:.4f}, test loss: {loss_b:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para limpiar los modelos en memoria. Opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_models(client_model: FlexModel, _):\n",
    "    import gc\n",
    "\n",
    "    client_model.clear()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen las rondas de entrenamiento del modelo federado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_rounds(n_rounds, clients_per_round=20):\n",
    "    pool = FlexPool.client_server_pool(\n",
    "        fed_dataset= flex_data, server_id=server_id, init_func=build_server_model\n",
    "    )\n",
    "    for i in range(n_rounds):\n",
    "        print(f\"\\nRunning round: {i+1} of {n_rounds}\")\n",
    "        selected_clients_pool = pool.clients.select(clients_per_round)\n",
    "        selected_clients = selected_clients_pool.clients\n",
    "        pool.servers.map(deploy_serv, selected_clients)\n",
    "        selected_clients.map(train)\n",
    "        pool.aggregators.map(collect_client_diff_weights_pt, selected_clients)\n",
    "        pool.aggregators.map(fed_avg)\n",
    "        pool.aggregators.map(set_aggregated_diff_weights_pt, pool.servers)\n",
    "        metrics = pool.servers.map(evaluate_global_model)\n",
    "        selected_clients.map(clean_up_models)\n",
    "        loss, acc = metrics[0]\n",
    "        print(f\"Server: Test acc: {acc:.4f}, test loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n_rounds(2, clients_per_round=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
